{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Run if you want to autoreload your personal modules on change\r\n",
    "import autoreload\r\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\r\n",
    "get_ipython().run_line_magic('autoreload', '2')\r\n",
    "#Next is needed in azure vm to autoreload modules in cwd\r\n",
    "import os\r\n",
    "pwd=os.popen(\"pwd\").read().rstrip()\r\n",
    "import sys\r\n",
    "sys.path.append(pwd)\r\n",
    "'''Train CIFAR10 with PyTorch.'''\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.backends.cudnn as cudnn\r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import numpy\r\n",
    "import sklearn\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import os\r\n",
    "import argparse\r\n",
    "#from models import *\r\n",
    "import utils\r\n",
    "#from utils import progress_bar\r\n",
    "import time\r\n",
    "from torchvision import models\r\n",
    "import model_actions\r\n",
    "import az_manage_proc\r\n",
    "import load\r\n",
    "import log\r\n",
    "import many_inj\r\n",
    "#import many_inj_ni\r\n",
    "from pytorchfi_c.core import fault_injection as pfi_core\r\n",
    "#from pytorchfi_ni.core import fault_injection as pfi_core\r\n",
    "print(\"GPU available: \",torch.cuda.is_available())\r\n",
    "print(\"OS: \",sys.platform)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Preparing data..\n",
      "Files already downloaded and verified\n",
      "GPU available:  True\n",
      "OS:  win32\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "num_batches = 100\r\n",
    "c,w,h=3,32,32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model=model_actions.load(\"checkpoints/bs_128_sch_plateau/bs_128_sch_plateau_epoch_160\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "model_actions.test(model.eval())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8552, 35.54125615954399)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#debug=True? num_batches?\r\n",
    "pfi_model = pfi_core(model.eval(), h, w, num_batches\r\n",
    ", c=c\r\n",
    "#,debug=True\r\n",
    ",use_cuda=torch.cuda.is_available())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "many_model = many_inj.many_n_inj(pfi_model,10000,min_val=0,max_val=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model_actions.test(many_model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8474, 37.113341212272644)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "%debug"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> \u001b[1;32mc:\\users\\gaboc\\desktop\\tesis\\azure download synchcronization\\thesis\\pytorchfi_ni\\core.py\u001b[0m(342)\u001b[0;36m_set_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    340 \u001b[1;33m        )\n",
      "\u001b[0m\u001b[1;32m    341 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 342 \u001b[1;33m        \u001b[0mlayerDim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLAYERS_DIM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_curr_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    343 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    344 \u001b[1;33m        logging.info(\n",
      "\u001b[0m\n",
      "[[1, 64, 16, 16], [1, 64, 8, 8], [1, 64, 8, 8], [1, 64, 8, 8], [1, 64, 8, 8], [1, 128, 4, 4], [1, 128, 4, 4], [1, 128, 4, 4], [1, 128, 4, 4], [1, 128, 4, 4], [1, 256, 2, 2], [1, 256, 2, 2], [1, 256, 2, 2], [1, 256, 2, 2], [1, 256, 2, 2], [1, 512, 1, 1], [1, 512, 1, 1], [1, 512, 1, 1], [1, 512, 1, 1], [1, 512, 1, 1]]\n",
      "20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "len(list(list(model.children())[0].children()))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dee0b18f5efeed97723793285cb915e0fd443adf8426f935c8cb81cf81e23c84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}