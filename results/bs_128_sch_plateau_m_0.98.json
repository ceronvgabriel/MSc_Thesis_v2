{"train_acc_v": [24.418, 34.692, 39.284, 43.388, 47.22, 50.24, 52.882, 55.89, 57.506, 59.088, 60.966, 62.138, 64.684, 64.884, 66.646, 67.55, 69.36, 69.932, 70.09, 71.184, 70.584, 71.52, 72.528, 72.612, 73.648, 72.742, 74.086, 74.726, 73.926, 74.51, 74.396, 79.488, 82.112, 82.74, 83.108, 83.948, 83.916, 84.358, 84.728, 84.914, 84.95, 85.32, 85.74, 86.242, 86.368, 86.336, 86.578, 86.706, 87.826, 88.056, 88.29, 88.232, 88.228, 88.456, 88.462, 88.494, 88.59, 88.82, 88.504, 88.824, 88.792, 88.836, 88.674, 88.916, 88.742, 88.834, 88.67, 88.688, 89.056, 88.842, 88.844, 88.854, 88.82, 88.872, 88.786, 88.676, 88.85, 88.79, 88.856, 88.774, 88.894, 88.806, 88.628, 88.954, 88.888, 88.768, 88.938, 88.79, 88.834, 88.802, 88.802, 88.958, 88.732, 88.962, 88.742, 88.866, 89.014, 88.764, 88.65, 88.762, 88.718, 88.77, 88.648, 88.722, 88.796, 88.898, 88.916, 88.966, 88.81, 88.968, 88.726, 88.726, 88.782, 88.714, 88.784, 88.732, 88.74, 88.886, 88.806, 88.914, 88.86, 88.686, 88.902, 88.752, 88.814, 88.798, 88.612, 89.006, 88.836, 88.792, 88.828, 88.75, 88.862, 88.634, 88.718, 88.842, 88.854, 88.814, 88.98, 88.936, 88.81, 88.928, 88.9, 88.842, 88.716, 88.664, 88.804, 88.762, 88.784, 88.702, 88.924, 88.882, 88.852, 88.858, 88.814, 88.648, 89.02, 88.94, 88.946, 88.9], "train_loss_v": [2.1764919746398927, 1.729758196144104, 1.6182242767715453, 1.5370852083587647, 1.4603646292114258, 1.4014730609130859, 1.3277437554931641, 1.2531345804214478, 1.2165227828216554, 1.1778010407829285, 1.133894923210144, 1.1082414750289917, 1.0434787172317506, 1.037505707397461, 0.9780088059806824, 0.9603232780075073, 0.9203402749633789, 0.8970861670684814, 0.8901715569877624, 0.8770734286499023, 0.8881763525390625, 0.8525703678512573, 0.8349264582633972, 0.8325490469741821, 0.7983873283767701, 0.8359913377761841, 0.7826107553482056, 0.7681708723640442, 0.7900990245246887, 0.7717686511993408, 0.7737207030487061, 0.6106710024547577, 0.5263094245529175, 0.5048614828395843, 0.4903556999588013, 0.4681630202293396, 0.46669774171829226, 0.457012391204834, 0.4422252503204346, 0.44010301446914674, 0.4326904501438141, 0.4210153346824646, 0.4123865976524353, 0.40534862743377686, 0.40059618795394897, 0.3908344925498962, 0.386901880569458, 0.38207749826431275, 0.34957725357055663, 0.3403452701282501, 0.3391629623508453, 0.3413408533859253, 0.33666918811798097, 0.3334347781944275, 0.3313417576122284, 0.33205818305015566, 0.3276888852214813, 0.32558948578834535, 0.3274826224708557, 0.3239470734786987, 0.32092950700759887, 0.3263148990058899, 0.322043869600296, 0.3216940181732178, 0.32397360780715945, 0.32203099349021913, 0.32512733868598936, 0.3238696787071228, 0.3200339956378937, 0.32190435252189636, 0.3223439543056488, 0.32383172832489016, 0.32316830543518066, 0.3223349586391449, 0.3247073279094696, 0.32590205498695374, 0.3230362548446655, 0.32274794445991517, 0.32126041988372805, 0.3237546679401398, 0.3216765748786926, 0.3237871935939789, 0.3262124921798706, 0.32008618925094606, 0.32147329396247865, 0.32353898645401, 0.3216311404800415, 0.3226984377479553, 0.325618676700592, 0.32366074562072755, 0.3238565923690796, 0.32126603231430056, 0.3223405288362503, 0.3223232775115967, 0.32249188808441165, 0.32288656213760375, 0.31852487203598023, 0.32547732785224914, 0.32549208528518675, 0.32883507259368894, 0.32371405706405637, 0.3233711286067963, 0.3242045005226135, 0.32408412758350374, 0.3235409529685974, 0.31992068059921264, 0.32246878485679625, 0.32339374013900757, 0.32485305938243864, 0.3225841282081604, 0.32134817224502565, 0.32217659303665164, 0.3260855255508423, 0.3226839746570587, 0.32398080660820006, 0.3252617303562164, 0.3239325909137726, 0.3215271906375885, 0.3238461901187897, 0.3215791667079926, 0.3232754745101929, 0.3231728433322906, 0.3194544907188416, 0.321903769493103, 0.32285145491600037, 0.32199117285728457, 0.32456088755607604, 0.31976001836776735, 0.32100459094047545, 0.32223880702018737, 0.3201258469104767, 0.3234803070020676, 0.32009311151504516, 0.32690128333091734, 0.3234938207912445, 0.32212092195510866, 0.3219514114379883, 0.3240352932548523, 0.31815834358215334, 0.31916311254501345, 0.323126531085968, 0.3236113718700409, 0.32437191858291625, 0.32435100934982297, 0.3233496812915802, 0.3248805443096161, 0.32252999850273134, 0.32189053484916685, 0.3237693033695221, 0.32472316507339477, 0.320482407040596, 0.3219891431427002, 0.3228327971696854, 0.32202029071807864, 0.32079215885162354, 0.32548361335754394, 0.32065037466049195, 0.3215741134357452, 0.3176913309955597, 0.3217262030506134], "test_acc_v": [32.57, 38.69, 42.98, 47.13, 50.71, 53.19, 57.9, 58.27, 57.71, 61.99, 62.32, 67.09, 66.01, 67.02, 68.44, 70.7, 67.9, 68.68, 70.56, 70.72, 71.11, 71.79, 72.51, 71.94, 76.03, 74.1, 76.5, 74.14, 74.06, 76.2, 74.7, 80.26, 81.56, 81.97, 82.25, 82.13, 82.93, 82.99, 83.08, 83.0, 83.08, 82.64, 83.26, 83.77, 83.53, 83.29, 83.19, 83.16, 84.14, 84.08, 84.22, 84.27, 84.15, 84.32, 84.31, 84.16, 84.35, 84.11, 84.12, 84.15, 84.18, 84.21, 84.25, 84.13, 83.99, 84.17, 84.36, 84.22, 83.9, 84.2, 84.21, 84.1, 84.15, 84.08, 84.24, 84.17, 84.29, 84.06, 84.16, 84.18, 84.24, 84.14, 84.09, 84.11, 84.13, 84.04, 84.22, 84.2, 84.23, 84.18, 84.07, 84.16, 84.09, 84.35, 84.18, 84.13, 84.06, 84.27, 84.03, 83.98, 84.31, 84.14, 84.11, 84.22, 84.13, 84.31, 83.96, 84.25, 84.18, 84.13, 84.26, 84.24, 84.14, 84.06, 84.1, 84.14, 84.24, 84.1, 84.03, 84.14, 84.32, 84.25, 84.13, 84.26, 84.22, 84.21, 84.04, 84.17, 84.18, 84.03, 84.09, 84.24, 84.06, 84.13, 84.18, 84.22, 84.1, 84.17, 84.11, 84.2, 84.08, 84.07, 84.2, 84.24, 84.15, 84.18, 84.16, 84.16, 84.22, 84.11, 84.1, 84.02, 84.05, 84.24, 84.04, 84.2, 84.13, 84.14, 84.17, 84.3], "test_loss_v": [1.7931119276046752, 1.662154312324524, 1.5318840295791627, 1.490546175956726, 1.3423861728668214, 1.3986080072402953, 1.2497870626449585, 1.199238317489624, 1.2213126438140869, 1.0914575204849244, 1.1272169869422912, 1.0076620582580567, 1.055361880874634, 0.980452680683136, 0.9190130131721497, 0.8969141710281372, 0.9775955372810364, 1.0189328652381897, 0.8789925552368164, 0.9051100563049317, 0.8909048234939575, 0.879114794254303, 0.8634175810813903, 0.8371051155090332, 0.7600544624328613, 0.7858062655448913, 0.7066665322780609, 0.8021662602424622, 0.7851665637969971, 0.7217004764556885, 0.7935340123176575, 0.5749859768867492, 0.5450387596607208, 0.5318253434896469, 0.5306224278688431, 0.5308498551845551, 0.5192477841615677, 0.5054045830249786, 0.5083515753984451, 0.5089553511619568, 0.5018214697360992, 0.5186798087358475, 0.49509346520900727, 0.48765047554969787, 0.4873145546913147, 0.4949795210123062, 0.5017931386947632, 0.4966955785512924, 0.47699729280471803, 0.4754145483493805, 0.47300798289775847, 0.4699661352396011, 0.4781396733045578, 0.47323384778499605, 0.47677720861434936, 0.4773643144607544, 0.46916845118999484, 0.47295010347366334, 0.47350893108844755, 0.47493127682209013, 0.4727620823383331, 0.4728928370475769, 0.4730002839803696, 0.4764819450855255, 0.47352422866821287, 0.47514728038311005, 0.47268321397304536, 0.4751708192110062, 0.4767987500667572, 0.4754690768003464, 0.4722689952135086, 0.4751853798866272, 0.4719246396780014, 0.47653210484981534, 0.4728894567966461, 0.4722803547382355, 0.4722461111545563, 0.47264686896800995, 0.4736467866897583, 0.4741395267486572, 0.47198873434066774, 0.4722727848291397, 0.4747306993246079, 0.4773483795166016, 0.4732580214500427, 0.47657172985076907, 0.4733046290397644, 0.47722992026805877, 0.4716722107172012, 0.4754407178878784, 0.47242326238155363, 0.47186004509925844, 0.4737790698289871, 0.4724494382143021, 0.47272103199958804, 0.4740087480545044, 0.4740875530481338, 0.4725077506065369, 0.4745943507909775, 0.48237830263376236, 0.47402894682884217, 0.474083572435379, 0.47668163928985596, 0.47321625175476073, 0.4743068911075592, 0.4742352141141892, 0.47443876159191134, 0.4737844455957413, 0.474686251449585, 0.47559716527462004, 0.47158351979255675, 0.4758234984636307, 0.47336254098415376, 0.4742929653406143, 0.47407029213905333, 0.47254526438713074, 0.4730561714887619, 0.4754665180683136, 0.4731633426189423, 0.47237237746715544, 0.47330662789344785, 0.47255509169101717, 0.4726307820320129, 0.47001877608299253, 0.47415582768917086, 0.4713966433525085, 0.474913382601738, 0.47461731219291686, 0.47341816170215606, 0.4777215631246567, 0.4757678958415985, 0.4736856412172317, 0.47304881138801574, 0.4714633177995682, 0.4744315133333206, 0.4746084094762802, 0.4737870140314102, 0.4735968582868576, 0.4721776991844177, 0.4739905868053436, 0.4732649868249893, 0.4738069394826889, 0.47341523780822753, 0.47622472319602965, 0.47335845556259154, 0.47324538977146147, 0.4737376569747925, 0.47475387487411497, 0.4710645832061768, 0.4741263404130936, 0.4747221725702286, 0.4751274046897888, 0.47475643322467803, 0.47102569041252135, 0.47432250854969027, 0.47335369942188266, 0.4745921182870865, 0.47315195133686067, 0.4744733487844467, 0.4732436641216278], "current_lr_v": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08], "parameters": "{'current_function': 'progressive_train_4', 'batch_size': 1024, 'n_workers': 6, 'optimizer': {'class': <class 'torch.optim.sgd.SGD'>, 'dict': {'lr': 0.1, 'momentum': 0.98, 'dampening': 0, 'weight_decay': 5e-05, 'nesterov': False}}, 'scheduler': {'class': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'dict': {'factor': 0.1, 'optimizer': SGD (\nParameter Group 0\n    dampening: 0\n    lr: 1.0000000000000005e-08\n    momentum: 0.98\n    nesterov: False\n    weight_decay: 5e-05\n), 'min_lrs': [0], 'patience': 3, 'verbose': False, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.001, 'threshold_mode': 'rel', 'best': 0.46916845118999484, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 160, '_last_lr': [1.0000000000000005e-08]}}}", "tot_time": 3987.386552381}