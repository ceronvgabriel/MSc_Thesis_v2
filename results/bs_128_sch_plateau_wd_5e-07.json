{"train_acc_v": [30.404, 44.004, 51.254, 57.108, 61.326, 64.192, 66.992, 69.098, 70.542, 72.13, 73.584, 74.72, 75.426, 76.536, 77.444, 77.79, 78.632, 79.378, 79.702, 80.622, 81.146, 81.704, 81.92, 82.356, 83.1, 83.67, 83.788, 83.93, 84.704, 84.636, 84.852, 85.366, 85.466, 85.972, 86.15, 86.434, 89.224, 90.134, 90.396, 90.95, 91.136, 91.14, 91.548, 91.482, 91.596, 91.58, 91.712, 91.568, 91.788, 91.754, 91.594, 91.558, 91.678, 91.666, 91.87, 91.768, 91.74, 91.586, 91.578, 91.7, 91.612, 91.64, 91.702, 91.708, 91.568, 91.518, 91.616, 91.436, 91.558, 91.538, 91.642, 91.734, 91.872, 91.588, 91.684, 91.616, 91.712, 91.712, 91.682, 91.782, 91.686, 91.57, 91.666, 91.564, 91.57, 91.598, 91.628, 91.576, 91.628, 91.768, 91.804, 91.67, 91.526, 91.748, 91.71, 91.792, 91.646, 91.76, 91.52, 91.604, 91.602, 91.812, 91.512, 91.696, 91.678, 91.784, 91.896, 91.91, 91.706, 91.534, 91.554, 91.66, 91.634, 91.76, 91.79, 91.618, 91.73, 91.572, 91.814, 91.666, 91.706, 91.654, 91.556, 91.864, 91.736, 91.686, 91.834, 91.678, 91.726, 91.638, 91.82, 91.808, 91.722, 91.92, 91.736, 91.766, 91.624, 91.542, 91.872, 91.63, 91.724, 91.496, 91.606, 91.636, 91.748, 91.708, 91.766, 91.656, 91.588, 91.81, 91.642, 91.576, 91.67, 91.73, 91.636, 91.572, 91.504, 91.666, 91.54, 91.604], "train_loss_v": [2.1514453286743165, 1.5307991444015503, 1.341032706565857, 1.199318175086975, 1.0862048259162902, 1.0072567461395263, 0.9306230007934571, 0.8768601861572266, 0.8346299029731751, 0.7969790875053405, 0.7583447720718384, 0.7219967270278931, 0.7002877061462403, 0.6761041045188904, 0.6448096301937103, 0.6331705602645874, 0.6106741075706482, 0.5868033892059327, 0.5793312941741944, 0.5558940381622315, 0.5397187630653382, 0.5267157596302032, 0.518515263223648, 0.5040544041824341, 0.48938814224243166, 0.4702404687309265, 0.4620630895423889, 0.4556507865142822, 0.4388266214942932, 0.43831845561027527, 0.42936348223686216, 0.4175806540489197, 0.41079667219161986, 0.3996354100227356, 0.39392516090393065, 0.38590337990760804, 0.3079016518497467, 0.28122419465065, 0.27103780935287475, 0.25956148740291596, 0.2566210437297821, 0.2534753637123108, 0.24223606231689454, 0.24073176424980164, 0.23717879766464234, 0.23878461186408997, 0.2345526835155487, 0.23870415813446044, 0.23488211518287658, 0.23461111318588257, 0.23477276482582093, 0.23386726240158082, 0.23867995212554932, 0.23322873999595642, 0.23257267840385437, 0.23530653222560882, 0.2331977265071869, 0.2385871584844589, 0.23776722878456116, 0.23385839198112487, 0.2397883891582489, 0.2359487862968445, 0.23573901799201966, 0.23472154326438904, 0.23827095130443574, 0.23625917713165284, 0.23681309965133668, 0.2397335891342163, 0.23709552867889405, 0.23753264877319336, 0.2380084319496155, 0.23583822714805602, 0.23135920019626618, 0.23576651013374328, 0.23393289043426513, 0.23731574939727784, 0.23620113978385926, 0.23198437180042267, 0.23235875500679015, 0.23480190457344055, 0.23599470795154573, 0.23596139584064485, 0.23464601724624634, 0.2367285629081726, 0.2389796587562561, 0.23708004548072814, 0.23447157757759093, 0.2400443787240982, 0.23546611389636993, 0.23383094800949097, 0.23374871706008912, 0.234413175573349, 0.23666365880489348, 0.23330893177986145, 0.2365915756702423, 0.23503009813308715, 0.23699057443618773, 0.2361286865901947, 0.23925908988952638, 0.23622614047527313, 0.23802389474868774, 0.2365697544193268, 0.2388384695529938, 0.23516444375038148, 0.23513536906242372, 0.23386603220939636, 0.23526750635623933, 0.23309237329006194, 0.23599885072231291, 0.23699840708732606, 0.23514627136230468, 0.23628021580696107, 0.23891514261245728, 0.23267655557632447, 0.2379295995235443, 0.23377416296958922, 0.23552578788757325, 0.2356516845035553, 0.23222593188762664, 0.23668283978462218, 0.2352829210948944, 0.23535651372909547, 0.23558424960136415, 0.23161392619132995, 0.23587195112228393, 0.23457991134166717, 0.23010062027454375, 0.23493798122406007, 0.23407712791442872, 0.23589549265861512, 0.23139950711250304, 0.23365825737953186, 0.23239275065422058, 0.23243441801071166, 0.23539272034168243, 0.23579193370819093, 0.23404489500045778, 0.23789842402458192, 0.23290851157188416, 0.2363539678478241, 0.234751241312027, 0.23799323841094971, 0.23760374249458313, 0.2364251331138611, 0.23606881104946137, 0.23413030285835265, 0.23359527022361756, 0.2387319475412369, 0.2381559635734558, 0.2361222445678711, 0.23658554540634155, 0.23896314428329468, 0.23477169964790345, 0.23400413765907288, 0.23829650979042052, 0.236559340634346, 0.23719209259033203, 0.2381386948490143, 0.23618325475215912, 0.23683940027236938], "test_acc_v": [42.49, 49.66, 54.63, 61.73, 64.66, 67.47, 67.97, 70.04, 69.14, 74.65, 74.97, 74.55, 75.64, 75.73, 77.09, 76.69, 77.52, 78.74, 76.85, 78.91, 79.65, 80.22, 78.76, 79.25, 79.6, 80.54, 79.62, 79.74, 80.08, 81.07, 81.03, 82.18, 81.01, 81.21, 81.52, 81.09, 83.54, 83.84, 84.23, 84.19, 83.99, 84.19, 84.26, 84.27, 84.31, 84.37, 84.32, 84.37, 84.29, 84.02, 84.36, 84.18, 84.24, 84.27, 84.43, 84.25, 84.26, 84.3, 84.29, 84.14, 84.35, 84.38, 84.07, 84.37, 84.21, 84.28, 84.24, 84.41, 84.45, 84.28, 84.27, 84.29, 84.33, 84.27, 84.23, 84.3, 84.1, 84.31, 84.28, 84.11, 84.17, 84.4, 84.22, 84.34, 84.2, 84.23, 84.27, 84.27, 84.11, 84.35, 84.28, 84.37, 84.18, 84.26, 84.4, 84.18, 84.23, 84.24, 84.35, 84.42, 84.2, 84.25, 84.36, 84.32, 84.44, 84.25, 84.22, 84.4, 84.35, 84.1, 84.32, 84.47, 84.36, 84.24, 84.25, 84.18, 84.21, 84.46, 84.29, 84.35, 84.32, 84.39, 84.33, 84.43, 84.44, 84.51, 84.2, 84.39, 84.29, 84.37, 84.41, 84.34, 84.39, 84.12, 84.31, 84.38, 84.52, 84.32, 84.38, 84.4, 84.22, 84.12, 84.39, 84.21, 84.3, 84.33, 84.42, 84.4, 84.28, 84.22, 84.26, 84.33, 84.39, 84.29, 84.4, 84.18, 84.33, 84.38, 84.27, 84.4], "test_loss_v": [1.5513053911209107, 1.3942778526306152, 1.268975182914734, 1.0883332263946532, 1.0218345628738403, 0.9505448064804077, 0.9230573775291443, 0.8614702287197114, 0.9105867992401123, 0.739811933517456, 0.7471146588802338, 0.7363887100219727, 0.7192904552936554, 0.7001980210781097, 0.6618464539051055, 0.6803941355705261, 0.6647071861743927, 0.617020307970047, 0.677704936504364, 0.6214048095226288, 0.6101375739097595, 0.6066966167926788, 0.6251207280635833, 0.6192240141391754, 0.6218564690113068, 0.5779617921352387, 0.6026896353721619, 0.6098652364730835, 0.5920240468502045, 0.5736075811386109, 0.5774974740982056, 0.5475389385938645, 0.5848302654981613, 0.5772116949796676, 0.5885160774230958, 0.5946556784152984, 0.522917210483551, 0.5207746696949005, 0.5257705551147461, 0.5265956685066223, 0.5303756499767304, 0.528385808801651, 0.529393889427185, 0.5315838906288147, 0.5314095969676972, 0.5276963288784027, 0.5341764553546906, 0.5292331367492675, 0.5320972968101502, 0.5401316806316375, 0.5277506815433503, 0.5359961887359619, 0.5327157307624817, 0.5307251205444335, 0.5271367207527161, 0.5412099805831909, 0.5325613482952118, 0.534953712272644, 0.5357561466217041, 0.5338002495288849, 0.534026749753952, 0.5314527202129364, 0.5385807756900788, 0.5276639013290405, 0.5341505609035492, 0.5294671985149384, 0.533514803314209, 0.526663425540924, 0.5307425219058991, 0.5335785500049591, 0.5312424607753754, 0.5312760887145996, 0.5304224928855896, 0.5288094342231751, 0.5293973803043366, 0.5322212933063507, 0.5370431758880615, 0.5350955358982086, 0.5270863336086273, 0.5438324638843537, 0.5364752743244171, 0.5321471467018127, 0.5376358953952789, 0.531170983505249, 0.5371353511333465, 0.5295596341133118, 0.5280228306293487, 0.5313570954799652, 0.5320522902011872, 0.5321061408996582, 0.5347164315700531, 0.5299860368251801, 0.5299693825721741, 0.5303220442295075, 0.528703080034256, 0.5341152180194855, 0.5365369020462036, 0.5268813752174377, 0.5311642805576324, 0.5337006800174713, 0.5337563912391663, 0.536401883649826, 0.5332212122440338, 0.5320088301658631, 0.5325731543064117, 0.5339589405536651, 0.5387028591156006, 0.533817604970932, 0.5331314786911011, 0.5472421873569489, 0.5346784393787384, 0.5278005551815033, 0.5315143285751343, 0.5390110918998718, 0.5376235757827759, 0.5335379518985748, 0.5383498550415039, 0.5345563252449036, 0.5354820368766785, 0.5317692146778107, 0.5319293044090271, 0.5321956387996674, 0.531133363199234, 0.5274292442321777, 0.5292561828613281, 0.5276627829074859, 0.5317008053302765, 0.5325398473739624, 0.5341027781486511, 0.5332719961166382, 0.5283487956523896, 0.5356532754421234, 0.5306407525539398, 0.5271795681953431, 0.5293102897644043, 0.5333803141593934, 0.5271340887069702, 0.5328418027400971, 0.529849738407135, 0.5343236950397492, 0.5471229645729065, 0.5524246694564819, 0.5307915523529053, 0.5401199334621429, 0.5368662616252899, 0.5338189098834991, 0.5335233467102051, 0.5293670602321625, 0.5394276256084443, 0.5387203583240509, 0.5383330208301544, 0.5339762079238891, 0.5261434218883514, 0.533828488111496, 0.5331990782260895, 0.5328064591884613, 0.5336052560806275, 0.5306954265594482, 0.5327344547748566, 0.5289744132041931], "current_lr_v": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08], "parameters": "{'current_function': 'progressive_train_4', 'batch_size': 1024, 'n_workers': 6, 'optimizer': {'class': <class 'torch.optim.sgd.SGD'>, 'dict': {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 5e-07, 'nesterov': False}}, 'scheduler': {'class': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'dict': {'factor': 0.1, 'optimizer': SGD (\nParameter Group 0\n    dampening: 0\n    lr: 1.0000000000000005e-08\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 5e-07\n), 'min_lrs': [0], 'patience': 3, 'verbose': False, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.001, 'threshold_mode': 'rel', 'best': 0.5207746696949005, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 160, '_last_lr': [1.0000000000000005e-08]}}}", "tot_time": 3898.957903862}