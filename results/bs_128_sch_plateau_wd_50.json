{"train_acc_v": [10.022, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], "train_loss_v": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "test_acc_v": [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], "test_loss_v": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "current_lr_v": [0.1, 0.1, 0.1, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.0010000000000000002, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 0.00010000000000000003, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-05, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000004e-06, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-07, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08, 1.0000000000000005e-08], "parameters": "{'current_function': 'progressive_train_4', 'batch_size': 1024, 'n_workers': 6, 'optimizer': {'class': <class 'torch.optim.sgd.SGD'>, 'dict': {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 50, 'nesterov': False}}, 'scheduler': {'class': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'dict': {'factor': 0.1, 'optimizer': SGD (\nParameter Group 0\n    dampening: 0\n    lr: 1.0000000000000005e-08\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 50\n), 'min_lrs': [0], 'patience': 3, 'verbose': False, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 160, '_last_lr': [1.0000000000000005e-08]}}}", "tot_time": 3823.0081407009966}