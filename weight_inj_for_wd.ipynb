{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%run imports.py"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Preparing data..\n",
      "Files already downloaded and verified\n",
      "GPU available:  True\n",
      "OS:  win32\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Set up Test Variables:\r\n",
    "\r\n",
    "#Test batch size\r\n",
    "num_batches=100\r\n",
    "\r\n",
    "transform_test = transforms.Compose([\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\r\n",
    "    ])\r\n",
    "\r\n",
    "testset = torchvision.datasets.CIFAR10(\r\n",
    "        root='./data', train=False, download=True, transform=transform_test)\r\n",
    "\r\n",
    "test_batch_size=int(numpy.shape(testset.data)[0]/num_batches)\r\n",
    "#test_batch_size=100\r\n",
    "\r\n",
    "testloader = torch.utils.data.DataLoader(\r\n",
    "    testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\r\n",
    "\r\n",
    "test_features, test_labels = next(iter(testloader))\r\n",
    "#Get num channels, width and height of input data\r\n",
    "c,w,h=list(test_features[0].size())\r\n",
    "#Batchsize, see load18.py or main.py for batch size\r\n",
    "num_batches=int(numpy.shape(testset.data)[0]/test_batch_size)\r\n",
    "\r\n",
    "from many_inj import progressive_inj_zero"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#For epoch 160, azure\r\n",
    "\r\n",
    "#wds=[0,5e-7,5e-5,5e-3]\r\n",
    "wds=[0]\r\n",
    "sch=\"plateau\"\r\n",
    "\r\n",
    "tot=100000\r\n",
    "step=10000\r\n",
    "n_exp=5\r\n",
    "bs=128\r\n",
    "\r\n",
    "def inj_zero_plateau_epoch_160():\r\n",
    "\r\n",
    "    for wd in wds:\r\n",
    "        print(\"Inj iteration: \" + str(wd))\r\n",
    "        name = \"bs_\"+str(bs)+\"_sch_\"+sch + \"_wd_\"+str(wd)\r\n",
    "        \r\n",
    "        path=\"./checkpoints/\"+ name\r\n",
    "        path_best= path + \"/\"+name+\"_epoch_160\"\r\n",
    "\r\n",
    "        model = model_actions.load(path_best)\r\n",
    "\r\n",
    "        pfi_model = pfi_core(model.eval(), h, w, test_batch_size, c=c,debug=True,use_cuda=torch.cuda.is_available())\r\n",
    "\r\n",
    "        res = many_inj.progressive_inj_zero(pfi_model,tot,step,n_exp=n_exp)\r\n",
    "\r\n",
    "        save_name = name + \"_inj_zero_tot_\" + str(tot)+\"_step_\" + str(step) + \"_nexp_\"+ str(n_exp) + \"_epoch_160\"\r\n",
    "        save_data={}\r\n",
    "        save_data[\"avg\"]=res[0]\r\n",
    "        save_data[\"std\"]=res[1]\r\n",
    "        save_data[\"loss_avg\"] = [2]\r\n",
    "        save_data[\"loss_std\"] = [3]\r\n",
    "        utils.save(save_data,save_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "az_manage_proc.run_and_delete(log.log_time,inj_zero_plateau_epoch_160)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inj iteration: 0\n",
      "Injection: 0 of 2\n",
      "Injection: 1 of 2\n",
      "Injection: 2 of 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit (conda)"
  },
  "interpreter": {
   "hash": "dee0b18f5efeed97723793285cb915e0fd443adf8426f935c8cb81cf81e23c84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}